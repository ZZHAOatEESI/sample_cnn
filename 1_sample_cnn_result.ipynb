{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from keras import layers\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, Activation, Flatten, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from __future__ import print_function\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.engine import Input, Model\n",
    "import numpy as np\n",
    "import random\n",
    "K.set_learning_phase(0)\n",
    "model = load_model('sample_cnn_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "partition = joblib.load('partition_sample_cnn.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(partition['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(3)\n",
    "label_idx = {'feces': 0 , 'tongue': 1, 'skin': 2}\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, label_idx, batch_size=32, dim=(5000,125,4),\n",
    "                 n_classes=3, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = label_idx\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim)\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, *self.dim))\n",
    "        y = np.empty((self.batch_size) , dtype=int)\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            # Store sample\n",
    "            x_tmp = joblib.load(ID)\n",
    "            label_tmp = ID.split('_')[1].split('.')[0]\n",
    "            idx = np.random.randint(x_tmp.shape[0], size=5000)\n",
    "            X[i,] = x_tmp[idx,:,:]\n",
    "\n",
    "            # Store class\n",
    "            y[i] = self.labels[label_tmp]\n",
    "\n",
    "        return X, keras.utils.to_categorical(y, num_classes=self.n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'batch_size': 64,\n",
    "          'n_classes': 3,\n",
    "          'shuffle': True}\n",
    "\n",
    "# Datasets\n",
    "\n",
    "# Generators\n",
    "training_generator = DataGenerator(partition['train'], label_idx, **params)\n",
    "testing_generator = DataGenerator(partition['test'], label_idx, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 5000, 125, 4)      0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv2D)               (None, 5000, 120, 4)      100       \n",
      "_________________________________________________________________\n",
      "bn0 (BatchNormalization)     (None, 5000, 120, 4)      20000     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 5000, 120, 4)      0         \n",
      "_________________________________________________________________\n",
      "max_pool_0 (MaxPooling2D)    (None, 5000, 30, 4)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 5000, 20, 16)      720       \n",
      "_________________________________________________________________\n",
      "bn1 (BatchNormalization)     (None, 5000, 20, 16)      20000     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 5000, 20, 16)      0         \n",
      "_________________________________________________________________\n",
      "max_pool_1 (MaxPooling2D)    (None, 5000, 10, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 5000, 1, 1)        161       \n",
      "_________________________________________________________________\n",
      "bn2 (BatchNormalization)     (None, 5000, 1, 1)        20000     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5000, 1, 1)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 5000)              0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 3)                 15003     \n",
      "=================================================================\n",
      "Total params: 75,984\n",
      "Trainable params: 45,984\n",
      "Non-trainable params: 30,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.51243501901626587, 0.828125]\n"
     ]
    }
   ],
   "source": [
    "acc = model.evaluate_generator(generator=testing_generator)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.34904084749081554, 0.86672794117647056]\n"
     ]
    }
   ],
   "source": [
    "acc = model.evaluate_generator(generator=training_generator)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
